{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215d0862-89d6-45a4-a025-c9224bb6f750",
   "metadata": {},
   "source": [
    "## Discussion Week 7\n",
    "\n",
    "Author: Eva Newby\n",
    "\n",
    "https://maro406.github.io/eds-232-machine-learning/discussion/week7.html\n",
    "\n",
    "## Introduction\n",
    "In this weekâ€™s discussion section, we will use a dataset containing tweets related to different disasters. For each observation (tweet), there is an outcome variable that classifies the disasters talked about in the tweet as real (1), or not (0). Rather than having multiple predictors as our X, we will have one predictor - the tweet. However, each individual word can be thought of as their own predictor, each contributing to predicting our outcome variable.\n",
    "\n",
    "## Data\n",
    "The dataset this week is a commonly used dataset for NLP (Natural Language Processing). The dataset can be found here. Disasters.csv includes a text variable, which contains the tweet as a string. Our target variable, target, is a binary outcome variable with 1 representing the disaster discussed as real, and 0 representing the disaster discussed as not real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb5c2c5-327d-4925-996d-bd199097b71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb71ca37-5710-43e7-aa38-520429bb7b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "fp = '/Users/ejnewby/MEDS/eds232-ml/EDS232-discussion/EDS232-dicsussion/data/disaster.csv - disaster.csv'\n",
    "\n",
    "print(os.path.exists(fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3546b55a-7067-41e6-bf34-6657186840f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "disaster = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1b0c5c-93bf-4758-a011-c08bad079d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaning text data\n",
    "def preprocess(text):\n",
    "    text = text.lower() # converting text to lower case\n",
    "    text=  text.strip()  # removing leading/trailing spaces\n",
    "    text=  re.sub(r'<.*?>','', text) # remove html syntax\n",
    "    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text) # remove reference numbers\n",
    "    text = re.sub(r'\\d',' ',text) # removing digits\n",
    "    text = re.sub(r'\\s+', ' ', text) # collapsing multiple spaces into a singl space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce5035f9-f7f5-431e-a32a-7288dd6a08c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1  our deeds are the reason of this earthquake ma...  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  all residents asked to shelter in place are be...  \n",
       "3       1   people receive wildfires evacuation orders in...  \n",
       "4       1  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply string cleaning to text variable\n",
    "disaster['clean_text'] = disaster['text'].apply(preprocess)\n",
    "disaster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7f73d4-de27-45fa-9f31-bbacab802eea",
   "metadata": {},
   "source": [
    "### What about stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff92630c-287e-41ab-a12d-92fba5ae1916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Words:\n",
      "['5th' 'awesome' 'capstone' 'crush' 'march' 'presentation' 'team']\n"
     ]
    }
   ],
   "source": [
    "# Proof that Tfidf vectorizer excludes stopwords\n",
    "stop_words = [\"On March 5th, I will crush my capstone presentation with my awesome team.\"]\n",
    "\n",
    "vectorizer_english = TfidfVectorizer(stop_words = 'english')\n",
    "X_english = vectorizer_english.fit_transform(stop_words)\n",
    "\n",
    "print(\"Remaining Words:\")\n",
    "print(vectorizer_english.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fef347-405d-4e39-a6b6-e48c6ab118c9",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45fdd43-77dd-457e-85bb-85d54f2d9f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(disaster['clean_text'], disaster['target'], test_size = ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30364c-6e3b-485e-8d20-e1d7aaec032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize words\n",
    "tfidf_vectorizer = TdifVectorizer(stop_words = 'english')\n",
    "X_train_tfdif = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfdif = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d7840-403b-4b59-ab57-dc3b1dd1531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a logistic regression model and fit to vectorized training data\n",
    "lr_model = LogisticRegression(random_state = 42)\n",
    "lr_model.fit(X_train_tfdif, y_train)\n",
    "y_pred = lr_model.predict(X_test_tfdif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720b96c-ac7c-4394-9540-61041723407e",
   "metadata": {},
   "source": [
    "## Logistic Regression Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a824ba-17f1-4aee-a10a-5475719d3829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea36d21-79a6-4cb7-92f6-4357d2866a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda 3 (EDS232)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
